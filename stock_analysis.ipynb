{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb2GJBcA81l8+Gh50f1vjH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtdatasci/Python/blob/main/stock_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio\n",
        "! pip install gnews\n",
        "! pip install transformers\n",
        "! pip install datetime\n",
        "! pip install matplotlib\n",
        "! pip install tensorflow\n",
        "! pip install GoogleNews\n",
        "! pip install pandas"
      ],
      "metadata": {
        "id": "P66Pc_WW49So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0_FKEyZn4eBZ"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from gnews import GNews\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from GoogleNews import GoogleNews"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SENTIMENT_ANALYSIS_MODEL = \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\"\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=SENTIMENT_ANALYSIS_MODEL)"
      ],
      "metadata": {
        "id": "6th4c_p_a99i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_articles(query):\n",
        "    googlenews = GoogleNews(lang=\"en\")\n",
        "    googlenews.search(query)\n",
        "    articles = googlenews.result()\n",
        "    return articles\n",
        "\n",
        "def analyze_article_sentiment(article):\n",
        "    sentiment = sentiment_analyzer(article[\"desc\"])[0]\n",
        "    article[\"sentiment\"] = sentiment\n",
        "    return article\n",
        "\n",
        "def extract_and_clean_titles(df):\n",
        "    values_list = []\n",
        "    if df.empty:\n",
        "        return values_list\n",
        "    for value in df['title']:\n",
        "        index = value.find('-')\n",
        "        extracted_value = value[:index] if index >= 0 else value\n",
        "        cleaned_value = extracted_value.replace('...', '')\n",
        "        values_list.append(cleaned_value)\n",
        "    return values_list\n",
        "\n",
        "def analyze_sentiments(values_list):\n",
        "    prediction = []\n",
        "    for news in values_list:\n",
        "        sentiment = sentiment_analyzer(news)\n",
        "        prediction.append(sentiment)\n",
        "    return prediction\n",
        "\n",
        "def calculate_weighted_average(predictions):\n",
        "    weighted_avg = 0\n",
        "    for i in predictions:\n",
        "        if i[0]['label'] == 'positive':\n",
        "            weighted_avg += 1 * i[0]['score']\n",
        "        elif i[0]['label'] == 'negative':\n",
        "            weighted_avg += -1 * i[0]['score']\n",
        "    weighted_avg /= len(predictions)\n",
        "    return weighted_avg\n",
        "\n",
        "def sentiment_pie_chart(predictions, stock, output_path='sentiment_pie_chart.png'):\n",
        "    positive_count = 0\n",
        "    negative_count = 0\n",
        "    neutral_count = 0\n",
        "    for item in predictions:\n",
        "        label = item[0]['label']\n",
        "        if label == 'positive':\n",
        "            positive_count += 1\n",
        "        elif label == 'negative':\n",
        "            negative_count += 1\n",
        "        elif label == 'neutral':\n",
        "            neutral_count += 1\n",
        "    labels = ['Positive', 'Negative', 'Neutral']\n",
        "    sizes = [positive_count, negative_count, neutral_count]\n",
        "    colors = ['#66BB6A', '#EF5350', '#42A5F5']\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, pctdistance=0.85)\n",
        "    center_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
        "    fig.gca().add_artist(center_circle)\n",
        "    ax.axis('equal')\n",
        "    plt.title('Sentiment Analysis Results for ' + stock + ' Stock')\n",
        "    plt.savefig(output_path)\n",
        "    plt.close(fig)\n",
        "    return output_path\n",
        "\n",
        "def convert_to_dataframe(analyzed_articles):\n",
        "    df = pd.DataFrame(analyzed_articles)\n",
        "    df[\"Title\"] = df.apply(lambda row: f'<a href=\"{row[\"link\"]}\" target=\"_blank\">{row[\"title\"]}</a>', axis=1)\n",
        "    df[\"Description\"] = df[\"desc\"]\n",
        "    df[\"Date\"] = df[\"date\"]\n",
        "\n",
        "    def sentiment_badge(sentiment):\n",
        "        colors = {\"negative\": \"red\", \"neutral\": \"gray\", \"positive\": \"green\"}\n",
        "        color = colors.get(sentiment, \"grey\")\n",
        "        return f'<span style=\"background-color: {color}; color: white; padding: 2px 6px; border-radius: 4px;\">{sentiment}</span>'\n",
        "\n",
        "    df[\"Sentiment\"] = df[\"sentiment\"].apply(lambda x: sentiment_badge(x[\"label\"]))\n",
        "    return df[[\"Sentiment\", \"Title\", \"Description\", \"Date\"]]\n",
        "\n",
        "def analyze_asset_sentiment(asset_name):\n",
        "    articles = fetch_articles(asset_name)\n",
        "    analyzed_articles = [analyze_article_sentiment(article) for article in articles]\n",
        "    df = convert_to_dataframe(analyzed_articles)\n",
        "    return df\n",
        "\n",
        "def main(stock):\n",
        "    articles = fetch_articles(stock + \" stock\")\n",
        "    if not articles:\n",
        "        return \"Not enough data, please increase timeframe\", None\n",
        "\n",
        "    df = pd.DataFrame(articles)\n",
        "    values_list = extract_and_clean_titles(df)\n",
        "    predictions = analyze_sentiments(values_list)\n",
        "    weighted_avg = calculate_weighted_average(predictions)\n",
        "    pie_chart_path = sentiment_pie_chart(predictions, stock)\n",
        "\n",
        "    if -0.10 <= weighted_avg <= 0.10:\n",
        "        sentiment_summary = f'{weighted_avg:.2f} (Stagnant)'\n",
        "    elif weighted_avg > 0.10:\n",
        "        sentiment_summary = f'{weighted_avg:.2f} (Positive)'\n",
        "    else:\n",
        "        sentiment_summary = f'{weighted_avg:.2f} (Negative)'\n",
        "\n",
        "    detailed_df = analyze_asset_sentiment(stock)\n",
        "    return sentiment_summary, pie_chart_path, detailed_df\n",
        "\n",
        "with gr.Blocks() as iface:\n",
        "    gr.Markdown(\"# Trading Asset Sentiment Analysis\")\n",
        "    input_stock = gr.Textbox(label=\"Stock Name\", lines=1, placeholder=\"Enter the name of the stock...\")\n",
        "\n",
        "    with gr.Row():\n",
        "        analyze_button = gr.Button(\"Analyze Sentiment\", size=\"sm\")\n",
        "\n",
        "    sentiment_summary = gr.Textbox(label=\"Sentiment Summary\")\n",
        "    sentiment_chart = gr.Image(label=\"Sentiment Distribution\")\n",
        "    articles_output = gr.Dataframe(headers=[\"Sentiment\", \"Title\", \"Description\", \"Date\"], datatype=[\"markdown\", \"html\", \"markdown\", \"markdown\"], wrap=False)\n",
        "\n",
        "    analyze_button.click(main, inputs=[input_stock], outputs=[sentiment_summary, sentiment_chart, articles_output])\n",
        "\n",
        "iface.queue().launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "tnBmy5wma9i0",
        "outputId": "8da882da-cd1d-4d6b-cd3e-2c196b780316"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d2923d4db3b6f4b031.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d2923d4db3b6f4b031.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}